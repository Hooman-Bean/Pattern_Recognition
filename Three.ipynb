{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13736d5f-7363-4e6e-90b2-b8eba04c4950",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, classification_report, f1_score\n",
    "import numpy as np\n",
    "from csv import reader\n",
    "\n",
    "# Load a CSV file\n",
    "def load_csv(filename, skip_header = True, return_names = True):\n",
    "    dataset = list()\n",
    "    labels = list()\n",
    "    names = list()\n",
    "    with open(filename, 'r') as file:\n",
    "        csv_reader = reader(file)\n",
    "        for row in csv_reader:\n",
    "            if not row:\n",
    "                continue\n",
    "            labels.append(row.pop())\n",
    "            dataset.append(row)\n",
    "        if return_names:\n",
    "            names = dataset[0:]\n",
    "        if skip_header:\n",
    "            dataset = dataset[1:]\n",
    "            labels = labels[1:]\n",
    "        if return_names:    \n",
    "            return np.array(dataset, dtype = 'float'), np.array(labels), np.array(names)\n",
    "        else:\n",
    "            return np.array(dataset, dtype = 'float'), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ce1cc87-5737-4f48-9933-b2051d734827",
   "metadata": {},
   "outputs": [],
   "source": [
    "data, labels, names = load_csv('Dry_Bean_Dataset.csv', skip_header = True)\n",
    "x_train, x_test, y_train, y_test = train_test_split(data, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6f5dbeb-fa5b-4736-9d2e-0e99a94810a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score of scikit-learn model is:  0.8991030930175596\n",
      "accuracy of scikit-learn model is:  0.8968557155451072\n"
     ]
    }
   ],
   "source": [
    "# Run scikitlearn LinearDiscriminatorAnalysis\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "lda.fit(x_train, y_train)\n",
    "y_predict_sk = lda.predict(x_test)\n",
    "print(\"f1 score of scikit-learn model is: \", f1_score(y_test, y_predict_sk, average=\"weighted\"))\n",
    "print(\"accuracy of scikit-learn model is: \", accuracy_score(y_test, y_predict_sk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2eae3ca9-ef7b-4a62-9437-327872ce629e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score for k= 1 :  0.7430042551125777\n",
      "accuracy for k= 1 :  0.7425800764031737\n",
      "f1_score for k= 2 :  0.7188554625542919\n",
      "accuracy for k= 2 :  0.7211284161034381\n",
      "f1_score for k= 3 :  0.7323300754501477\n",
      "accuracy for k= 3 :  0.7331766088745225\n",
      "f1_score for k= 4 :  0.732438492041275\n",
      "accuracy for k= 4 :  0.7337643255950632\n",
      "f1_score for k= 5 :  0.7291556783249703\n",
      "accuracy for k= 5 :  0.7317073170731707\n",
      "f1_score for k= 6 :  0.7251346412577437\n",
      "accuracy for k= 6 :  0.7272994416691155\n",
      "f1_score for k= 7 :  0.7242536713142261\n",
      "accuracy for k= 7 :  0.7278871583896562\n",
      "f1_score for k= 8 :  0.7170758577499978\n",
      "accuracy for k= 8 :  0.7208345577431678\n",
      "f1_score for k= 9 :  0.7176511053470879\n",
      "accuracy for k= 9 :  0.7223038495445195\n",
      "f1_score for k= 10 :  0.711513638153381\n",
      "accuracy for k= 10 :  0.7155451072583014\n",
      "maximum f1 score was for k= 1\n",
      "maximum accuracy was for k= 1\n"
     ]
    }
   ],
   "source": [
    "# Run scikitlearn KNearestNeighbour\n",
    "f1s = list()\n",
    "accs = list()\n",
    "for i in range(1,11):\n",
    "    knn = KNeighborsClassifier(n_neighbors=i)\n",
    "    knn.fit(x_train, y_train)\n",
    "    y_pred = knn.predict(x_test)\n",
    "    f1s.append(f1_score(y_test, y_pred, average=\"weighted\"))\n",
    "    accs.append(accuracy_score(y_test, y_pred))\n",
    "    \n",
    "f1_scores = np.array(f1s)\n",
    "accuracies = np.array(accs)\n",
    "\n",
    "for i in range(len(f1_scores)):\n",
    "    print(\"f1_score for k=\", i + 1, \": \", f1_scores[i])\n",
    "    print(\"accuracy for k=\", i + 1, \": \", accuracies[i])\n",
    "\n",
    "print(\"maximum f1 score was for k=\", np.argmax(f1_scores) + 1)\n",
    "print(\"maximum accuracy was for k=\", np.argmax(accuracies) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b610c86d-5a4d-4a02-b2ff-f572661b379b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score:  0.762156953122046\n",
      "accuracy:  0.76461945342345\n"
     ]
    }
   ],
   "source": [
    "# Run scikitlearn NaiveBayes\n",
    "nb = GaussianNB()\n",
    "nb.fit(x_train, y_train)\n",
    "y_pred = nb.predict(x_test)\n",
    "print(\"f1 score: \", f1_score(y_test, y_pred, average=\"weighted\"))\n",
    "print(\"accuracy: \", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4bc7601c-d0d6-46a8-bf1c-d305d1b29ff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracies: [0.1340433345574734, 0.25459221160911094, 0.17707567964731816, 0.949669360764144, 0.28545187362233654]\n",
      "Mean Accuracy: 36.017%\n",
      "F1 Scores: [0.1743816090691616, 0.18120223038450375, 0.10108546992627684, 0.9739062896625441, 0.44412689339811373]\n",
      "Mean F1 Scores: 37.494%\n"
     ]
    }
   ],
   "source": [
    "# Run k-fold validation with k=5\n",
    "kf = KFold(n_splits = 5)\n",
    "kf.get_n_splits(data)\n",
    "accuracies = list()\n",
    "f1_scores = list()\n",
    "for trainIdx, testIdx in kf.split(data):\n",
    "    lda.fit(data[trainIdx], labels[trainIdx])\n",
    "    predictions = lda.predict(data[testIdx])\n",
    "    acc = accuracy_score(labels[testIdx], predictions)\n",
    "    f1s = f1_score(labels[testIdx], predictions, average=\"weighted\")\n",
    "    accuracies.append(acc)\n",
    "    f1_scores.append(f1s)\n",
    "print('Accuracies: %s' % accuracies)\n",
    "print('Mean Accuracy: %.3f%%' % ((sum(accuracies)/float(len(accuracies)))*100))\n",
    "print('F1 Scores: %s' % f1_scores)\n",
    "print('Mean F1 Scores: %.3f%%' % ((sum(f1_scores)/float(len(f1_scores)))*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a53f5629-0277-4565-b0be-bb52bc09bd0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracies: [0.906720528828498, 0.9011756061719324, 0.8989713445995592, 0.9099926524614255, 0.9088905216752388]\n",
      "Mean Accuracy: 90.515%\n",
      "F1 Scores: [0.9082060266453551, 0.9029563827242272, 0.9006770311592911, 0.9111949299314627, 0.9110413344357047]\n",
      "Mean F1 Scores: 90.682%\n"
     ]
    }
   ],
   "source": [
    "# Run k-fold validation with k=5 & shuffle\n",
    "kf = KFold(n_splits = 5, shuffle=True)\n",
    "kf.get_n_splits(data)\n",
    "accuracies = list()\n",
    "f1_scores = list()\n",
    "for trainIdx, testIdx in kf.split(data):\n",
    "    lda.fit(data[trainIdx], labels[trainIdx])\n",
    "    predictions = lda.predict(data[testIdx])\n",
    "    acc = accuracy_score(labels[testIdx], predictions)\n",
    "    f1s = f1_score(labels[testIdx], predictions, average=\"weighted\")\n",
    "    accuracies.append(acc)\n",
    "    f1_scores.append(f1s)\n",
    "print('Accuracies: %s' % accuracies)\n",
    "print('Mean Accuracy: %.3f%%' % ((sum(accuracies)/float(len(accuracies)))*100))\n",
    "print('F1 Scores: %s' % f1_scores)\n",
    "print('Mean F1 Scores: %.3f%%' % ((sum(f1_scores)/float(len(f1_scores)))*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "70b6c020-74fe-40a2-b557-cb08e6c06d22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracies: [0.7653323540213001, 0.9695077149155034, 0.9669360764144012, 0.9397501836884644, 0.6711976487876561]\n",
      "Mean Accuracy: 86.254%\n",
      "F1 Scores: [0.758035804722464, 0.9692123692086694, 0.9668636825111037, 0.9403375446209, 0.6170139729117534]\n",
      "Mean F1 Scores: 85.029%\n"
     ]
    }
   ],
   "source": [
    "# Run k-fold validation with k=5 using StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits = 5)\n",
    "skf.get_n_splits(data, labels)\n",
    "accuracies = list()\n",
    "f1_scores = list()\n",
    "for trainIdx, testIdx in skf.split(data, labels):\n",
    "    lda.fit(data[trainIdx], labels[trainIdx])\n",
    "    predictions = lda.predict(data[testIdx])\n",
    "    acc = accuracy_score(labels[testIdx], predictions)\n",
    "    f1s = f1_score(labels[testIdx], predictions, average=\"weighted\")\n",
    "    accuracies.append(acc)\n",
    "    f1_scores.append(f1s)\n",
    "print('Accuracies: %s' % accuracies)\n",
    "print('Mean Accuracy: %.3f%%' % ((sum(accuracies)/float(len(accuracies)))*100))\n",
    "print('F1 Scores: %s' % f1_scores)\n",
    "print('Mean F1 Scores: %.3f%%' % ((sum(f1_scores)/float(len(f1_scores)))*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1df1998f-8839-4967-96eb-20303d46f5a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracies: [0.910025706940874, 0.8956649522409993, 0.9070536370315944, 0.9008082292432035, 0.9070536370315944]\n",
      "Mean Accuracy: 90.412%\n",
      "F1 Scores: [0.9114533882383399, 0.8976919261067821, 0.9083331394014968, 0.9025886551038372, 0.9089952896337384]\n",
      "Mean F1 Scores: 90.581%\n"
     ]
    }
   ],
   "source": [
    "# Run k-fold validation with k=5 using StratifiedKFold & shuffle\n",
    "skf = StratifiedKFold(n_splits = 5, shuffle=True)\n",
    "skf.get_n_splits(data, labels)\n",
    "accuracies = list()\n",
    "f1_scores = list()\n",
    "for trainIdx, testIdx in skf.split(data, labels):\n",
    "    lda.fit(data[trainIdx], labels[trainIdx])\n",
    "    predictions = lda.predict(data[testIdx])\n",
    "    acc = accuracy_score(labels[testIdx], predictions)\n",
    "    f1s = f1_score(labels[testIdx], predictions, average=\"weighted\")\n",
    "    accuracies.append(acc)\n",
    "    f1_scores.append(f1s)\n",
    "print('Accuracies: %s' % accuracies)\n",
    "print('Mean Accuracy: %.3f%%' % ((sum(accuracies)/float(len(accuracies)))*100))\n",
    "print('F1 Scores: %s' % f1_scores)\n",
    "print('Mean F1 Scores: %.3f%%' % ((sum(f1_scores)/float(len(f1_scores)))*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb0eb391-5282-4a2e-b0e3-c983cbe7f17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Linear Discriminator Analysis classifier had the best accuracy of: 0.9030267411107846"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
