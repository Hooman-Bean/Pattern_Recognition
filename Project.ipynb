{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1aaee47-8366-46e5-ac53-a9ed0916f22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3afd4e60-367f-4bf9-84ba-dfb029abd362",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleveland Heart Dataset\n",
    "heart_data = pd.read_csv(\"processed_cleveland.csv\")\n",
    "# Replace missing data with the mean of the column (imputing data)\n",
    "# Replace '?' with NaN\n",
    "heart_data = heart_data.replace('?', np.nan)\n",
    "# Convert columns to float\n",
    "heart_data = heart_data.astype(float)\n",
    "# Replace NaN with mean of column\n",
    "heart_data = heart_data.apply(lambda x: x.fillna(x.mean()),axis=0)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(heart_data.drop('goal', axis=1), heart_data['goal'], test_size=0.3, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5f51906-6afa-4c14-bfc4-e3e6dd1d9324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build Naive Bayes model with unscaled data\n",
    "nb = GaussianNB()\n",
    "nb.fit(X_train, y_train)\n",
    "y_pred = nb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c8d5644-17e1-41d7-8c50-13277db31187",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build LDA model with unscaled data\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "lda.fit(X_train, y_train)\n",
    "y_predict_sk = lda.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee5331e5-c1eb-4fbd-a999-5abbf2d83fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build KNN model(using GridSearch to find the best k using 5-fold validation) with unscaled data\n",
    "knn = KNeighborsClassifier()\n",
    "param_grid = {'n_neighbors': np.arange(1, 25)}\n",
    "knn_gscv = GridSearchCV(knn, param_grid, cv=5)\n",
    "knn_gscv.fit(X_train, y_train)\n",
    "# save the best model\n",
    "knn = knn_gscv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0399914f-c4c1-4457-b0b5-4743efb5165d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build SVM model(using GridSearch to find the best kernel) with unscaled data\n",
    "svm = SVC()\n",
    "param_grid = {'kernel': ['linear', 'poly', 'rbf', 'sigmoid']}\n",
    "svm_gscv = GridSearchCV(svm, param_grid, cv=5)\n",
    "svm_gscv.fit(X_train, y_train)\n",
    "# save the best model\n",
    "svm = svm_gscv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "420d0d86-ce08-4142-8e98-97c9561fdecc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build NN model with unscaled data\n",
    "nn = MLPClassifier()\n",
    "nn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c6705da-1393-44a1-9696-d612a6a60175",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build Logistic Regression model with unscaled data\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1bc2b1b3-8b2e-4672-a66e-bdf35ba059ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB accuracy:  0.5824175824175825\n",
      "LDA accuracy:  0.5934065934065934\n",
      "KNN accuracy:  0.4945054945054945\n",
      "SVM accuracy:  0.5934065934065934\n",
      "NN accuracy:  0.5604395604395604\n",
      "Logistic Regression accuracy:  0.5934065934065934\n"
     ]
    }
   ],
   "source": [
    "# check accuracies of individual models with unscaled data\n",
    "print(\"NB accuracy: \", nb.score(X_test, y_test))\n",
    "print(\"LDA accuracy: \", lda.score(X_test, y_test))\n",
    "print(\"KNN accuracy: \", knn.score(X_test, y_test))\n",
    "print(\"SVM accuracy: \", svm.score(X_test, y_test))\n",
    "print(\"NN accuracy: \", nn.score(X_test, y_test))\n",
    "print(\"Logistic Regression accuracy: \", log_reg.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "556a82e2-96db-4012-8a4a-6adb503f5570",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble voting classifier on unscaled Cleveland Heart dataset:  0.5714285714285714\n"
     ]
    }
   ],
   "source": [
    "#create a dictionary of our models\n",
    "estimators=[('nb',nb),('lda',lda),('knn', knn), ('svm', svm), ('nn', nn), ('log_reg', log_reg)]\n",
    "#create our voting classifier, inputting our models, using voting='hard' to select by majority vote\n",
    "ensemble = VotingClassifier(estimators, voting='hard')\n",
    "#fit model to training data\n",
    "ensemble.fit(X_train, y_train)\n",
    "#test our model on the test data\n",
    "print(\"Ensemble voting classifier on unscaled Cleveland Heart dataset: \", ensemble.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "19d5d283-8ac7-460a-8f20-c49065e7e0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the data\n",
    "X_scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler to the training data\n",
    "X_scaler.fit(X_train)\n",
    "\n",
    "# Scale the training and test data\n",
    "X_train = X_scaler.transform(X_train)\n",
    "X_test = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9b664c14-ae3e-48dc-8139-9f450670ce58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build Naive Bayes model with scaled data\n",
    "nb = GaussianNB()\n",
    "nb.fit(X_train, y_train)\n",
    "y_pred = nb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "861041f6-d309-499d-97ee-dfb5f96592af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build LDA model with scaled data\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "lda.fit(X_train, y_train)\n",
    "y_predict_sk = lda.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7a16dba1-1b9c-421f-b692-7b94c38e15a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build KNN model(using GridSearch to find the best k using 5-fold validation) with scaled data\n",
    "knn = KNeighborsClassifier()\n",
    "param_grid = {'n_neighbors': np.arange(1, 25)}\n",
    "knn_gscv = GridSearchCV(knn, param_grid, cv=5)\n",
    "knn_gscv.fit(X_train, y_train)\n",
    "# save the best model\n",
    "knn = knn_gscv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "560f434a-127c-472b-8986-e9d716156932",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build SVM model(using GridSearch to find the best kernel) with scaled data\n",
    "svm = SVC()\n",
    "param_grid = {'kernel': ['linear', 'poly', 'rbf', 'sigmoid']}\n",
    "svm_gscv = GridSearchCV(svm, param_grid, cv=5)\n",
    "svm_gscv.fit(X_train, y_train)\n",
    "# save the best model\n",
    "svm = svm_gscv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "af532fdd-7d1a-47b1-baca-15d699579e84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier()"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build NN model with scaled data\n",
    "nn = MLPClassifier()\n",
    "nn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "50d539bc-2ab9-4a1d-90f7-f93113de3ff4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build Logistic Regression model with scaled data\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "42a00cf2-f96c-43b4-8840-72936431159e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB accuracy:  0.5824175824175825\n",
      "LDA accuracy:  0.5934065934065934\n",
      "KNN accuracy:  0.6043956043956044\n",
      "SVM accuracy:  0.6043956043956044\n",
      "NN accuracy:  0.5824175824175825\n",
      "Logistic Regression accuracy:  0.5604395604395604\n"
     ]
    }
   ],
   "source": [
    "# check accuracies of individual models with scaled data\n",
    "print(\"NB accuracy: \", nb.score(X_test, y_test))\n",
    "print(\"LDA accuracy: \", lda.score(X_test, y_test))\n",
    "print(\"KNN accuracy: \", knn.score(X_test, y_test))\n",
    "print(\"SVM accuracy: \", svm.score(X_test, y_test))\n",
    "print(\"NN accuracy: \", nn.score(X_test, y_test))\n",
    "print(\"Logistic Regression accuracy: \", log_reg.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bb453b64-3c64-4e4b-a363-e972b1cf4632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble voting classifier on scaled Cleveland Heart dataset:  0.5934065934065934\n"
     ]
    }
   ],
   "source": [
    "#create a dictionary of our models\n",
    "estimators=[('nb',nb),('lda',lda),('knn', knn), ('svm', svm), ('nn', nn), ('log_reg', log_reg)]\n",
    "#create our voting classifier, inputting our models, using voting='hard' to select by majority vote\n",
    "ensemble = VotingClassifier(estimators, voting='hard')\n",
    "#fit model to training data\n",
    "ensemble.fit(X_train, y_train)\n",
    "#test our model on the test data\n",
    "print(\"Ensemble voting classifier on scaled Cleveland Heart dataset: \", ensemble.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "57e52721-94c8-459a-a65b-18bb251d9333",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dry Beans Dataset\n",
    "bean_data = pd.read_csv(\"Dry_Bean_Dataset.csv\")\n",
    "\n",
    "# Encode the Class values as integers\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(bean_data['Class'])\n",
    "encoded_Y = encoder.transform(bean_data['Class'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(bean_data.drop('Class', axis=1), encoded_Y, test_size=0.3, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "be6519df-7821-4f20-b5c2-1bfb4079429e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build Naive Bayes model with unscaled data\n",
    "nb = GaussianNB()\n",
    "nb.fit(X_train, y_train)\n",
    "y_pred = nb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "874ef199-6776-4578-8c6f-e9f8adb7caf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build LDA model with unscaled data\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "lda.fit(X_train, y_train)\n",
    "y_predict_sk = lda.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cb8ec122-6638-4350-ac17-a7292ab81216",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build KNN model(using GridSearch to find the best k using 5-fold validation) with unscaled data\n",
    "knn = KNeighborsClassifier()\n",
    "param_grid = {'n_neighbors': np.arange(1, 25)}\n",
    "knn_gscv = GridSearchCV(knn, param_grid, cv=5)\n",
    "knn_gscv.fit(X_train, y_train)\n",
    "# save the best model\n",
    "knn = knn_gscv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e385dbb2-4d7e-4e72-bb2d-8087abad0a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build SVM model(using GridSearch to find the best kernel) with unscaled data\n",
    "svm = SVC()\n",
    "param_grid = {'kernel': ['linear', 'poly', 'rbf', 'sigmoid']}\n",
    "svm_gscv = GridSearchCV(svm, param_grid, cv=5)\n",
    "svm_gscv.fit(X_train, y_train)\n",
    "# save the best model\n",
    "svm = svm_gscv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f33ce239-82fc-4ebd-963c-d293ddd13c3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier()"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build NN model with unscaled data\n",
    "nn = MLPClassifier()\n",
    "nn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "eec3e364-4e96-4af7-83ab-061376ddf763",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build Logistic Regression model with unscaled data\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "426cbb78-e00d-41a8-8493-d120f9696007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB accuracy:  0.7659157688540646\n",
      "LDA accuracy:  0.9094025465230167\n",
      "KNN accuracy:  0.7416748285994124\n",
      "SVM accuracy:  0.9177277179236043\n",
      "NN accuracy:  0.3922624877571009\n",
      "Logistic Regression accuracy:  0.7029872673849168\n"
     ]
    }
   ],
   "source": [
    "# check accuracies of individual models with unscaled data\n",
    "print(\"NB accuracy: \", nb.score(X_test, y_test))\n",
    "print(\"LDA accuracy: \", lda.score(X_test, y_test))\n",
    "print(\"KNN accuracy: \", knn.score(X_test, y_test))\n",
    "print(\"SVM accuracy: \", svm.score(X_test, y_test))\n",
    "print(\"NN accuracy: \", nn.score(X_test, y_test))\n",
    "print(\"Logistic Regression accuracy: \", log_reg.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e7a05d93-9509-4448-86a9-8459630af917",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble voting classifier on unscaled Dry Beans dataset:  0.8780607247796278\n"
     ]
    }
   ],
   "source": [
    "#create a dictionary of our models\n",
    "estimators=[('nb',nb),('lda',lda),('knn', knn), ('svm', svm), ('nn', nn), ('log_reg', log_reg)]\n",
    "\n",
    "#create our voting classifier, inputting our models, using voting='hard' to select by majority vote\n",
    "ensemble = VotingClassifier(estimators, voting='hard')\n",
    "\n",
    "#fit model to training data\n",
    "ensemble.fit(X_train, y_train)\n",
    "\n",
    "#test our model on the test data\n",
    "print(\"Ensemble voting classifier on unscaled Dry Beans dataset: \", ensemble.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "27e7462c-8cde-4864-b9ec-e49f436cbaa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the data\n",
    "X_scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler to the training data\n",
    "X_scaler.fit(X_train)\n",
    "\n",
    "# Scale the training and test data\n",
    "X_train = X_scaler.transform(X_train)\n",
    "X_test = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c89c412c-2203-42af-ab26-ccd76f6d6be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build Naive Bayes model with scaled data\n",
    "nb = GaussianNB()\n",
    "nb.fit(X_train, y_train)\n",
    "y_pred = nb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f3279b2b-35dc-47b4-b77c-e80db04b6774",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build LDA model with scaled data\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "lda.fit(X_train, y_train)\n",
    "y_predict_sk = lda.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5b89a744-a333-463a-97b4-86955a5a4f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build KNN model(using GridSearch to find the best k using 5-fold validation) with scaled data\n",
    "knn = KNeighborsClassifier()\n",
    "param_grid = {'n_neighbors': np.arange(1, 25)}\n",
    "knn_gscv = GridSearchCV(knn, param_grid, cv=5)\n",
    "knn_gscv.fit(X_train, y_train)\n",
    "# save the best model\n",
    "knn = knn_gscv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0dd12964-4baa-40b9-8d64-a823ae38d10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build SVM model(using GridSearch to find the best kernel) with scaled data\n",
    "svm = SVC()\n",
    "param_grid = {'kernel': ['linear', 'poly', 'rbf', 'sigmoid']}\n",
    "svm_gscv = GridSearchCV(svm, param_grid, cv=5)\n",
    "svm_gscv.fit(X_train, y_train)\n",
    "# save the best model\n",
    "svm = svm_gscv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "df9b3d7d-af44-43e5-b4de-eeeff745507f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier()"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build NN model with scaled data\n",
    "nn = MLPClassifier()\n",
    "nn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b5f67eae-05f3-49a0-b874-42f1e2be618a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build Logistic Regression model with scaled data\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "218953dd-13ac-4065-affd-aaeb45f3c237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB accuracy:  0.9000979431929481\n",
      "LDA accuracy:  0.9094025465230167\n",
      "KNN accuracy:  0.9231145935357493\n",
      "SVM accuracy:  0.9309500489715965\n",
      "NN accuracy:  0.9289911851126347\n",
      "Logistic Regression accuracy:  0.9223800195886386\n"
     ]
    }
   ],
   "source": [
    "# check accuracies of individual models with scaled data\n",
    "print(\"NB accuracy: \", nb.score(X_test, y_test))\n",
    "print(\"LDA accuracy: \", lda.score(X_test, y_test))\n",
    "print(\"KNN accuracy: \", knn.score(X_test, y_test))\n",
    "print(\"SVM accuracy: \", svm.score(X_test, y_test))\n",
    "print(\"NN accuracy: \", nn.score(X_test, y_test))\n",
    "print(\"Logistic Regression accuracy: \", log_reg.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4c8558e9-02fc-4cd2-9689-80f1f1476185",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble voting classifier on scaled Dry Beans dataset:  0.9292360430950048\n"
     ]
    }
   ],
   "source": [
    "#create a dictionary of our models\n",
    "estimators=[('nb',nb),('lda',lda),('knn', knn), ('svm', svm), ('nn', nn), ('log_reg', log_reg)]\n",
    "#create our voting classifier, inputting our models, using voting='hard' to select by majority vote\n",
    "ensemble = VotingClassifier(estimators, voting='hard')\n",
    "#fit model to training data\n",
    "ensemble.fit(X_train, y_train)\n",
    "#test our model on the test data\n",
    "print(\"Ensemble voting classifier on scaled Dry Beans dataset: \", ensemble.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a231df24-c6a3-4306-87cc-78c85378c0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.\tWhich of the following achieved higher accuracy?\n",
    "#- b.\tThe classifier trained on the scaled dry bean dataset\n",
    "#2.\tWhich of the following achieved higher accuracy?\n",
    "#- b.\tThe classifier trained on the scaled Cleveland heart dataset\n",
    "#3.\tDid any of the individual classifiers achieve higher accuracy than the voting classifiers? If so, list the individual classifier(s) and give a brief explanation of why/how this occurred.\n",
    "#- Yes, lDA classifier on scaled data and SVM classifier on both scaled and unscaled achieved higher accuracy than the voting classifier. As LDA classifier is linear in nature it performed better with scaled data as compared to ensemble voting classifier which averages the best possible result from other classfiers.\n",
    "# The SVM classifier achieved better results than ensemble voting classifier for both scaled and unscaled data because,hard ensemble voting classifier choses the highest weighted mean for the result amongst the other classifier which is not as good as SVM classifier for large datasets, as SVM classifier can choose different kernels for different datasets, it is better in accuracy and storage for large datsets. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
